# /// script
# title = "Copick Tomogram Visualization Server"
# description = "A FastAPI server that extends copick-server to provide visualization of tomogram samples."
# author = "Kyle Harrington <czi@kyleharrington.com>"
# license = "MIT"
# version = "0.0.3"
# keywords = ["tomogram", "visualization", "fastapi", "copick", "server"]
# classifiers = [
#     "Development Status :: 3 - Alpha",
#     "Intended Audience :: Science/Research",
#     "License :: OSI Approved :: MIT License",
#     "Programming Language :: Python :: 3.9",
#     "Topic :: Scientific/Engineering :: Bio-Informatics",
#     "Topic :: Scientific/Engineering :: Visualization"
# ]
# requires-python = ">=3.10"
# dependencies = [
#     "numpy",
#     "matplotlib",
#     "fastapi",
#     "uvicorn",
#     "zarr<3",
#     "numcodecs<0.16.0",  
#     "copick>=0.8.0",
#     "copick-torch @ git+https://github.com/copick/copick-torch.git",
#     "copick-server @ git+https://github.com/copick/copick-server.git"
# ]
# ///

"""
Copick Tomogram Visualization Server

A FastAPI server that extends copick-server to provide visualization of tomogram samples.
Displays central slices and average projections along all axes for tomogram samples.
"""

import os
import io
import base64
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Optional, Dict, Any, Union
from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import HTMLResponse
import uvicorn
import threading
import tempfile
import json
from matplotlib.colors import LinearSegmentedColormap

# Import from copick-server
from copick_server.server import CopickRoute
from fastapi.middleware.cors import CORSMiddleware
import copick

# Import from copick-torch
import copick_torch
from copick_torch.copick import CopickDataset
from copick_torch import SimpleCopickDataset, ClassBalancedSampler, MixupAugmentation
from torch.utils.data import DataLoader

# Extended CopickDataset that loads all object classes
class ExtendedCopickDataset(SimpleCopickDataset):
    """Extended version of SimpleCopickDataset that properly loads all objects."""
    
    def _load_data(self):
        """Load particle picks data from copick project with full object listing."""
        # Determine which root to use
        if self.copick_root is not None:
            root = self.copick_root
            print(f"Using provided copick root object")
        else:
            try:
                root = copick.from_file(self.config_path)
                print(f"Loading data from {self.config_path}")
            except Exception as e:
                print(f"Failed to load copick root: {str(e)}")
                return

        # Initialize keys list by first getting all pickable objects
        self._keys = []
        try:
            for obj in root.pickable_objects:
                if obj.type == "Particle":
                    self._keys.append(obj.name)
            print(f"Found {len(self._keys)} pickable objects: {', '.join(self._keys)}")
        except Exception as e:
            print(f"Error loading pickable objects: {str(e)}")
        
        # Store all particle coordinates for background sampling
        all_particle_coords = []
        
        for run in root.runs:
            print(f"Processing run: {run.name}")
            
            # Try to load tomogram
            try:
                voxel_spacing_obj = run.get_voxel_spacing(self.voxel_spacing)
                if voxel_spacing_obj is None or not hasattr(voxel_spacing_obj, 'tomograms') or not voxel_spacing_obj.tomograms:
                    print(f"No tomograms found for run {run.name} at voxel spacing {self.voxel_spacing}")
                    continue
                    
                tomogram = voxel_spacing_obj.tomograms[0]
                tomogram_array = tomogram.numpy()
            except Exception as e:
                print(f"Error loading tomogram for run {run.name}: {str(e)}")
                continue

            # Process picks
            run_particle_coords = []  # Store coordinates for this run
            
            for picks in run.get_picks():
                if not picks.from_tool:
                    continue
                    
                object_name = picks.pickable_object_name
                
                try:
                    points, _ = picks.numpy()
                    points = points / self.voxel_spacing
                    
                    for point in points:
                        try:
                            x, y, z = point
                            
                            # Save for background sampling
                            run_particle_coords.append((x, y, z))
                            
                            # Extract subvolume
                            subvolume, is_valid, _ = self._extract_subvolume_with_validation(
                                tomogram_array, x, y, z
                            )
                            
                            if is_valid:
                                self._subvolumes.append(subvolume)
                                
                                if object_name not in self._keys:
                                    self._keys.append(object_name)
                                
                                self._molecule_ids.append(self._keys.index(object_name))
                                self._is_background.append(False)
                        except Exception as e:
                            print(f"Error extracting subvolume: {str(e)}")
                except Exception as e:
                    print(f"Error processing picks for {object_name}: {str(e)}")
            
            # Sample background points for this run if needed
            if self.include_background and run_particle_coords:
                all_particle_coords.extend(run_particle_coords)
                self._sample_background_points(tomogram_array, run_particle_coords)
        
        self._subvolumes = np.array(self._subvolumes)
        self._molecule_ids = np.array(self._molecule_ids)
        self._is_background = np.array(self._is_background)

        # Apply max_samples limit if specified
        if self.max_samples is not None and len(self._subvolumes) > self.max_samples:
            indices = np.random.choice(len(self._subvolumes), self.max_samples, replace=False)
            self._subvolumes = self._subvolumes[indices]
            self._molecule_ids = self._molecule_ids[indices]
            self._is_background = self._is_background[indices]
        
        print(f"Loaded {len(self._subvolumes)} subvolumes with {len(self._keys)} classes")
        print(f"Background samples: {sum(self._is_background)}")

# Port configuration - define once and reuse
PORT = 8018
HOST = "0.0.0.0"

# Create a new FastAPI app and add our custom routes first
app = FastAPI()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/tomogram-viz", response_class=HTMLResponse)
async def visualize_tomograms(
    dataset_id: int = Query(..., description="Dataset ID"),
    overlay_root: str = Query("/tmp/test/", description="Overlay root directory"),
    run_name: Optional[str] = Query(None, description="Run name to visualize (if None, uses first run)"),
    voxel_spacing: Optional[float] = Query(None, description="Voxel spacing to use (if None, uses first available)"),
    tomo_type: str = Query("wbp", description="Tomogram type (e.g., 'wbp')"),
    batch_size: int = Query(25, description="Number of samples to visualize"),
    box_size: int = Query(64, description="Box size for subvolume extraction"),
    slice_colormap: str = Query("gray", description="Colormap for slices"),
    projection_colormap: str = Query("viridis", description="Colormap for projections"),
    augment: bool = Query(True, description="Apply augmentations"),
    show_augmentations: bool = Query(False, description="Show augmentation stages"),
    use_balanced_sampling: bool = Query(True, description="Use class balanced sampling"),
    background_ratio: float = Query(0.2, description="Ratio of background samples")
):
    """
    Visualize tomogram samples from a CoPick dataset, showing central slices and average projections
    along all axes.
    
    Args:
        dataset_id: Dataset ID from CZ cryoET Data Portal
        overlay_root: Root directory for the overlay storage
        run_name: Name of the run to visualize
        voxel_spacing: Voxel spacing to use
        tomo_type: Tomogram type (e.g., 'wbp')
        batch_size: Number of samples to visualize
        box_size: Box size for subvolume extraction
        slice_colormap: Matplotlib colormap for slices
        projection_colormap: Matplotlib colormap for projections
    
    Returns:
        HTML page with visualizations
    """
    try:
        # Create a temporary config file for the dataset
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
            config_path = temp_file.name
            
            # Load the dataset using the copick API
            root = copick.from_czcdp_datasets([dataset_id], overlay_root=overlay_root)
            
            # Save the config to a file for CopickDataset to use
            # config_data = root._config.model_dump(exclude_unset=True)
            # json.dump(config_data, temp_file, indent=4)
        
        # Get available runs
        runs = root.runs
        if not runs:
            raise HTTPException(status_code=404, detail="No runs found in the dataset")
        
        # Select the run to use
        selected_run = None
        if run_name:
            for run in runs:
                if str(run.meta.name) == run_name:
                    selected_run = run
                    break
            if selected_run is None:
                raise HTTPException(status_code=404, detail=f"Run {run_name} not found in the dataset")
        else:
            selected_run = runs[0]
            run_name = str(selected_run.meta.name)
        
        # Get available voxel spacings
        voxel_spacings = [vs.meta.voxel_size for vs in selected_run.voxel_spacings]
        if not voxel_spacings:
            raise HTTPException(status_code=404, detail=f"No voxel spacings found for run {run_name}")
        
        # Select the voxel spacing to use
        if voxel_spacing is None:
            voxel_spacing = voxel_spacings[0]
        elif voxel_spacing not in voxel_spacings:
            # Find the closest voxel spacing
            voxel_spacing = min(voxel_spacings, key=lambda vs: abs(vs - voxel_spacing))
        
        # Get the tomograms for the selected run and voxel spacing
        voxel_spacing_obj = selected_run.get_voxel_spacing(voxel_spacing)
        tomograms = voxel_spacing_obj.get_tomograms(tomo_type)
        if not tomograms:
            raise HTTPException(status_code=404, detail=f"No tomograms found for run {run_name} with voxel spacing {voxel_spacing} and type {tomo_type}")
        
        # Create the dataset using our extended class
        dataset = ExtendedCopickDataset(
            copick_root=root,
            # config_path=config_path,
            boxsize=(box_size, box_size, box_size),
            voxel_spacing=voxel_spacing,
            augment=augment,
            include